{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e35afe16",
   "metadata": {},
   "source": [
    "### K-means clustering: text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eca69be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.set_printoptions(precision = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6fabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# This function returns:\n",
    "# - a matrix X with one row per document (review). Each row is a sparse\n",
    "# vector containing tf.idf term weights for the words in the document.\n",
    "# - the vectorizor used to create X\n",
    "# - the actual reviews used as input to the vectorizer\n",
    "\n",
    "def get_beer_reviews_vectorized(top_n = -1, ngram_range = (1,1), max_features = 1000):\n",
    "    df = pd.read_csv('./assets/beer2.csv')['text']\n",
    "    df = df.dropna()   # drop any rows with empty reviews\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, max_features=max_features,\n",
    "                                 min_df=2, stop_words='english',\n",
    "                                 ngram_range = ngram_range,\n",
    "                                 use_idf=True)\n",
    "    if (top_n >= 0):\n",
    "        review_instances = df.values[0:top_n]\n",
    "    else:\n",
    "        review_instances = df.values\n",
    "    \n",
    "    X = vectorizer.fit_transform(review_instances) \n",
    "    \n",
    "    return (X, vectorizer, review_instances)\n",
    "\n",
    "def print_cluster_features(vectorizer, centroids, n_clusters, top_n_features):\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(n_clusters):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in centroids[i, :top_n_features]:\n",
    "            print(' [%s]' % terms[ind], end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4307b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the first 5000 entries (reviews)\n",
    "\n",
    "(X, vectorizer, review_instances) = get_beer_reviews_vectorized(5000, (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8e0720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7.103724957438545, 66.36912593606624],\n",
       " [9.35040755232012, 51.20285111664583],\n",
       " [9.592438827030367, 40.613123398634784],\n",
       " [8.197282591441104, 42.95571301600999],\n",
       " [8.287681685515773, 38.14493770875936],\n",
       " [7.976206385944393, 35.09722200514752],\n",
       " [7.955940974835473, 31.8349341264373],\n",
       " [7.743336777219178, 29.53090074292199]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score\n",
    "scores = []\n",
    "for i in range(2,10):\n",
    "    kmeans = KMeans(n_clusters = i, init='k-means++', max_iter=100, n_init=1, random_state=42)\n",
    "    model = kmeans.fit_predict(X)\n",
    "    db_score = davies_bouldin_score(X.toarray(), model)\n",
    "    model = kmeans.fit(X)\n",
    "    labels = model.labels_\n",
    "    ch_score = calinski_harabasz_score(X.toarray(), labels)\n",
    "    scores.append([db_score,ch_score])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb7cdee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means:  2\n",
      "Davies-Bouldin Score:  7.1\n",
      "Calinski-Harabsz Score:  66.37\n",
      "\n",
      "\n",
      "k-means:  3\n",
      "Davies-Bouldin Score:  9.35\n",
      "Calinski-Harabsz Score:  51.2\n",
      "\n",
      "\n",
      "k-means:  4\n",
      "Davies-Bouldin Score:  9.59\n",
      "Calinski-Harabsz Score:  40.61\n",
      "\n",
      "\n",
      "k-means:  5\n",
      "Davies-Bouldin Score:  8.2\n",
      "Calinski-Harabsz Score:  42.96\n",
      "\n",
      "\n",
      "k-means:  6\n",
      "Davies-Bouldin Score:  8.29\n",
      "Calinski-Harabsz Score:  38.14\n",
      "\n",
      "\n",
      "k-means:  7\n",
      "Davies-Bouldin Score:  7.98\n",
      "Calinski-Harabsz Score:  35.1\n",
      "\n",
      "\n",
      "k-means:  8\n",
      "Davies-Bouldin Score:  7.96\n",
      "Calinski-Harabsz Score:  31.83\n",
      "\n",
      "\n",
      "k-means:  9\n",
      "Davies-Bouldin Score:  7.74\n",
      "Calinski-Harabsz Score:  29.53\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k_value in range(len(scores)):\n",
    "    print(\"k-means: \", k_value+2)\n",
    "    print(\"Davies-Bouldin Score: \", round(scores[k_value][0],2))\n",
    "    print(\"Calinski-Harabsz Score: \", round(scores[k_value][1],2))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8fac6f",
   "metadata": {},
   "source": [
    "The two evaluation metrics we will be using for this K-means algorithm are the Davies-Bouldin score, and the Calinski-Harabsz score. The value **k = 2** minimizes Davies-Bouldin score while maximizing the Calinski-Harabsz score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f29c5b",
   "metadata": {},
   "source": [
    "Now that we have chosen a value for k, we will find what the predominant terms are in the resulting clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c8a5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: [chocolate] [coffee] [dark] [roasted] [black] [brown] [stout] [nice] [like] [malt]\n",
      "Cluster 1: [nice] [hops] [good] [light] [sweet] [malt] [like] [bit] [hop] [white]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 2, init='k-means++', max_iter=100, n_init=1, random_state=42)\n",
    "kmeans.fit(X)\n",
    "centroid =  kmeans.cluster_centers_\n",
    "sort_centroid = np.argsort(-1*centroid)\n",
    "print_cluster_features(vectorizer, sort_centroid, n_clusters =2, top_n_features = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c963b77",
   "metadata": {},
   "source": [
    "##### The words above were simply the words in a typical review for each cluster, but some words such as \"like\" and \"nice\" appear in both clusters. It would be more informative to find words that are specific (or discriminative) to clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feacd6b6",
   "metadata": {},
   "source": [
    "Information gain (IG) helps find features that distinguish one class from another, improving prediction accuracy. We don't have labels, but we use the same idea to find terms that are special to a cluster, this distinguishing that cluster from another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e11633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "def compute_distinctive_term_score(T, T_a):   \n",
    "    # First compute information gain.\n",
    "    IG = entropy(T) - entropy(T_a) \n",
    "          \n",
    "    # if it's high IG, but not for this class, we want to penalize,\n",
    "    # so flip the IG negative.  We do this because these are terms those whose *absence* is notable, \n",
    "    # we give them a score that guarantees we won't rank them highly.\n",
    "    if (T_a[0] < T_a[1]):\n",
    "        score = -IG  \n",
    "    else:\n",
    "        score = IG\n",
    "    return score\n",
    "\n",
    "# create a 1-vs-all two-class matrix for each cluster\n",
    "def one_vs_all_count_matrix(m, index):\n",
    "    # row zero is the selected row\n",
    "    row0 = m[index, :]\n",
    "    # row one is the other rows summed\n",
    "    row1 = np.vstack((m[0:index, :], m[index+1:, :])).sum(axis=0)\n",
    "              \n",
    "    result = np.vstack((row0, row1))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd851de6",
   "metadata": {},
   "source": [
    "#### Here are the steps I followed to reach information gain based distinctive terms:\n",
    "1. Run k-means again but this time setting k=7 to give a slightly more diverse set of clusters to start with.\n",
    "\n",
    "\n",
    "2. Get the cluster-term matrix of cluster centers $L$ from the result of k-means, an array with seven rows, one row per cluster, and 1000 columns (one column per word/term in the vocabulary produced by the vectorizer).\n",
    "\n",
    "\n",
    "3. For each row $c$ in $L$,  (for each cluster)\n",
    "\n",
    "    a. For this cluster, we're going to compute a 'distinctive term score' for each of the terms/words in the vocabulary. To do this, we're going to compute how surprised we are at the distribution $T_w$ of a word $w$ between this cluster vs all other clusters, compared to the distribution $T_c$ of the average word between this cluster $c$ and all clusters. If a word is a lot more likely to occur in this cluster than we would expect by chance, it is considered a more distinctive word for this cluster. This surprise factor is *information gain*. \n",
    "    \n",
    "    Te variable $T_c$ has two possible values: \"in this cluster $c$\" and \"in any other cluster\". Each of these outcomes has a probability when we're talking about where words occur.\n",
    "    \n",
    "    The function `one_vs_all_count_matrix` makes it easy to compute $T_c$. As input, you provide the matrix $L$ along with the row $c$ you want to analyze. The output is a \"one versus all\" matrix $M$ that has shape (2, 1000): the first row has the weights of words in *this* cluster $c$ (which is the same as L[c, :]), and the second row has the aggregate summed weights of the words across all *other* clusters. \n",
    "    \n",
    "    b. To compute $T_c$, compute $M$ and sum over all columns. Then to turn it into a probability distribution, normalize by computing `T_c = T_c / sum(T_c)`.\n",
    "    \n",
    "    c. Now we loop through each column $i$ of $L$. We'll call the term corresponding to the $i$-th column, term $w$. So for each term $w$ we'll compute the second part we need: the term-specific distribution $T_w$ for that specific term $w$ in this cluster vs all clusters. \n",
    "    \n",
    "    $T_w$ is the $i$-th column of the one-vs-all matrix $M$ (term weight in this cluster, term weight in all other clusters)  again normalized by computing 'T_w = T_w / sum(T_w)'. \n",
    "    \n",
    "    Then use the `compute_distinctive_term_score` function to compute the information gain for that term. The first argument is $T_c$ computed for all words, and the second argument is $T_w$ just for this term $w$. \n",
    "    \n",
    "    d. After looping through all terms in (c) above, we have a result list with 1000 entries, one per term, containing the distinctive score for each term, for that cluster $c$.\n",
    "    \n",
    "    e. Get the most distinctive terms for this cluster $c$ by sorting the array by descending score and selecting the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6182066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['vintage', 'sugar', 'toffee', 'nuts', 'barleywine'],\n",
       " ['pumpkin pie', 'pumpkin ale', 'pumpkin beer', 'pumpkin', 'orange color'],\n",
       " ['woody', 'apple', 'wood', 'peach', 'apples'],\n",
       " ['pale malt', 'light bodied', 'inch head', 'grain', 'pils'],\n",
       " ['caramel malt', 'sticky lacing', 'bitter hops', 'hop', 'hop bite'],\n",
       " ['marzen', 'bar', 'went', 'sam', 'oktoberfest'],\n",
       " ['roasted coffee', 'opaque', 'imperial', 'dark brown', 'colored head']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X, vectorizer, review_instances) = get_beer_reviews_vectorized(5000, (1,2))\n",
    "\n",
    "def cluster_features(vectorizer, centroids, n_clusters, top_n_features):\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    final_list = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster_list = []\n",
    "        for ind in centroids[i, :top_n_features]:\n",
    "            cluster_list.append(terms[ind])\n",
    "        final_list.append(cluster_list)\n",
    "    return final_list\n",
    "\n",
    "def cluster_labeling():\n",
    "    # Step 1\n",
    "    kmeans = KMeans(n_clusters = 7, init='k-means++', max_iter=100, n_init=1, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    # Step 2\n",
    "    L =  kmeans.cluster_centers_\n",
    "    result_list = []\n",
    "    \n",
    "    # Step 3\n",
    "    for k in range(7):\n",
    "        # Step 3a\n",
    "        M = one_vs_all_count_matrix(L,k)\n",
    "        \n",
    "        # Step 3b\n",
    "        T_c = np.sum(M, axis=1)\n",
    "        T_c = T_c / sum(T_c)\n",
    "        \n",
    "        # Step 3c\n",
    "        for i in range(1000):\n",
    "            T_w = M[:,i]\n",
    "            T_w = T_w / sum(T_w)\n",
    "            \n",
    "            # Step 3d\n",
    "            result_list.append(compute_distinctive_term_score(T_c, T_w))\n",
    "            \n",
    "    # Step 3e\n",
    "    result_reshape =np.reshape(result_list, (7,1000))\n",
    "    sort_result = np.argsort(-1*np.array(result_reshape))   \n",
    "    result = cluster_features(vectorizer, sort_result, n_clusters =7, top_n_features = 5)\n",
    "    return result\n",
    "cluster_labeling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67f4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
